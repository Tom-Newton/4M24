{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import uniform\n",
    "from scipy.stats import norm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 align=\"center\"><b><u>Lecture 2 - The Monte Carlo Method</u></b></h1>\n",
    "\n",
    "<h2>Importance Sampling</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook implements the importance sampling example seen in Lecture 2, and compares the efficency of this to the standard Monte Carlo method.\n",
    "\n",
    "The example attempts to estimate the probability that a component will last more than 7 years, given that the lifetimes are distributed $T_{\\text{life}} \\sim \\mathcal{N}(0,1)$.  We want to use Monte Carlo methods to esetimate the following expectation:\n",
    "\n",
    "$$\n",
    "\\begin{eqnarray*}\n",
    "\t\t\tI = P(T_{\\text{life}} \\geq 7) &=& \\mathbb{E}\\{I_{\\{T_{\\text{life}}\\geq7\\}}\\}\\\\\n",
    "\t\t\t                                    &=& \\int_{-\\infty}^{+\\infty}I_{\\{x\\geq7\\}}{\\cal N}(0,1)dx\\\\\n",
    "\t\t\t                                    &=& \\int_{-\\infty}^{+\\infty}I_{\\{x\\geq7\\}}\\frac{1}{\\sqrt{2\\pi}} \\exp\\left\\{-\\frac{x^2}{2}\\right\\}dx\n",
    "\\end{eqnarray*}\n",
    "$$\n",
    "\n",
    "This can theoretically estimated using:\n",
    "\n",
    "$$\n",
    "\\frac{1}{N} \\sum_{i=1}^{N} I_{\\{X^{(i)} \\geq 25\\}}\n",
    "$$\n",
    "with each $X^{(i)} \\sim \\mathcal{N}(0,1)$\n",
    "\n",
    "However, this will not work in practice.  We can calculate this expectation analytically, using the Gaussian CDF, giving the result below. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I = 1.2798651027878805e-12\n"
     ]
    }
   ],
   "source": [
    "mu = 7\n",
    "I = 1 - norm.cdf(x=mu,loc=0,scale=1)\n",
    "print(\"I = {}\".format(I))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This means that for a single sample to have a contribution to the estimate, on average $1/I$ samples must be taken.  The cell below calculates how long this notebook would take to produce a single, relevant sample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time to collect a non-rejected sample: 226.0 days\n"
     ]
    }
   ],
   "source": [
    "from timeit import timeit\n",
    "s_per_loop = timeit(lambda:norm.rvs(),number=10000)/10000\n",
    "secs = s_per_loop * (1/I)\n",
    "days = secs/(60*60*24)\n",
    "\n",
    "print(\"Time to collect a non-rejected sample: {} days\".format(round(days)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is completely impractical.  The solution to this is the importance sampler.  A new density, $q(x)$, is chosen such that $q(x)\\neq0$ when $p(x)\\neq0$ (recall $X^{(i)} \\sim p(x)$).  This new density is aligned with the important regions of the space.  Since we are considering a lifetime of 7 years or more, the important region of space is almost all concentrated around $T_{\\text{life}}=7$.  A sensible choice for the new density could be $q(x) = \\mathcal{N}(7,1)$.  Samples $\\{X^{i}\\}_{i=1}^N$ are now taken from this density instead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 1000\n",
    "qx_samples = norm.rvs(size=N,loc=mu,scale=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The importance sampling estimate requires a different weighting of each sample, defined below:\n",
    "\n",
    "$$\n",
    "I = \\mathbb{E}_p \\{f(X)\\} = \\mathbb{E}_q \\{\\frac{f(X)p(X)}{q(X)}\\}\n",
    "$$\n",
    "\n",
    "so the estimate becomes:\n",
    "\n",
    "$$\n",
    "I^{*} = \\frac{1}{N}\\sum_{i=1}^{N} \\frac{f(X^{(i)})p(X^{(i)})}{q(X^{(i)})}\n",
    "$$\n",
    "\n",
    "The function below gives the importance weight for each sample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def importance(x):\n",
    "    if x>=mu:\n",
    "        return norm.pdf(x,loc=0,scale=1)/norm.pdf(x,loc=mu,scale=1)\n",
    "    else: \n",
    "        return 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The importance sampling estimate is shown below, and compared to the true expectation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True P: 1.2798651027878805e-12, Importance Sampling Estimate: 1.2728770227394743e-12\n"
     ]
    }
   ],
   "source": [
    "MCE = (1/N) * sum([importance(x) for x in qx_samples])\n",
    "print(\"True P: {}, Importance Sampling Estimate: {}\".format(I,MCE))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The importance sampler is able to form accurate estimates efficiently by suggesting a new density that covers the more important regions of space."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
